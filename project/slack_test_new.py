import threading
import json
import os
import torch
from flask import Flask, request, make_response, send_file
from slack_sdk import WebClient
from slack_sdk.errors import SlackApiError
from datetime import datetime
import numpy as np

# Matplotlib ë°±ì—”ë“œ ì„¤ì • (ê°€ì¥ ìƒë‹¨ì— ìœ„ì¹˜)
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt

import io
import re
import seaborn as sns

# IBM Watsonx AI ê´€ë ¨ ëª¨ë“ˆ ì„í¬íŠ¸
from dotenv import load_dotenv
from ibm_watsonx_ai import APIClient
from ibm_watsonx_ai.foundation_models import Embeddings
from ibm_watsonx_ai.metanames import EmbedTextParamsMetaNames as EmbedParams
from langchain_ibm import WatsonxLLM
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.cluster import KMeans

# Flask ì• í”Œë¦¬ì¼€ì´ì…˜ ì´ˆê¸°í™”
app = Flask(__name__)

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# Slack API í† í°
bot_token = os.getenv("SLACK_BOT_TOKEN")

# IBM API í‚¤ ë° í”„ë¡œì íŠ¸ ID
IBM_API_KEY = os.getenv("IBM_API_KEY")
PROJECT_ID = os.getenv("PROJECT_ID")

# í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜ ì²´í¬
if not bot_token:
    raise EnvironmentError("SLACK_BOT_TOKEN is not set!")

if not IBM_API_KEY or not PROJECT_ID:
    raise EnvironmentError("IBM_API_KEY or PROJECT_ID is not set!")

# Slack WebClient ì„¤ì •
client = WebClient(token=bot_token)
print("Slack client initialized")

# ë¡œì»¬ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
# LOCAL_IMAGE_PATH = 'C:/Users/HB/Downloads/desktopAPP/desktopAPP/thegull_profile_photoes/thegull_smile.png'

# ì´ë¯¸ì§€ ì œê³µ ì—”ë“œí¬ì¸íŠ¸
# @app.route('/deguli_profile_image')
# def deguli_profile_image():
#     return send_file(LOCAL_IMAGE_PATH, mimetype='image/png')

# IBM Watsonx AI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
wx_credentials = {
    "url": "https://us-south.ml.cloud.ibm.com",
    "apikey": IBM_API_KEY
}

# APIClient ì´ˆê¸°í™”
wx_client = APIClient(wx_credentials)

if wx_client:
    print("IBM Watsonx AI Client initialized successfully.")
else:
    print("Failed to initialize IBM Watsonx AI Client.")

# ì„ë² ë”© ëª¨ë¸ ì„¤ì •
EMBEDDING_MODEL_ID = wx_client.foundation_models.EmbeddingModels.MULTILINGUAL_E5_LARGE

embed_params = {
    EmbedParams.TRUNCATE_INPUT_TOKENS: 128,
    EmbedParams.RETURN_OPTIONS: {
        'input_text': True
    }
}

# ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
embedding_model = Embeddings(
    model_id=EMBEDDING_MODEL_ID,
    credentials=wx_credentials,
    params=embed_params,
    project_id=PROJECT_ID,
    space_id=None,
    verify=False
)

# LLM ëª¨ë¸ ì„¤ì •
os.environ["WATSONX_APIKEY"] = IBM_API_KEY

MODEL_ID_list = {
    'mistral-large': 'mistralai/mistral-large',
    'mixtral-8x7b': 'mistralai/mixtral-8x7b-instruct-v01',
    'llama3-70b': 'meta-llama/llama-3-1-70b-instruct',
    'llama3-8b': 'meta-llama/llama-3-1-8b-instruct',
}

parameters = {
    "decoding_method": "greedy",
    "max_new_tokens": 500,
    "repetition_penalty": 1.1,
    # "stop_sequences": ["\n"],  # ë¬¸ì œê°€ ë°œìƒí•˜ë©´ ì œê±°
}

MODEL_NAME = 'llama3-70b'

watsonx_llm = WatsonxLLM(
    model_id=MODEL_ID_list[MODEL_NAME],
    url="https://us-south.ml.cloud.ibm.com",
    project_id=PROJECT_ID,
    params=parameters,
)

# í•œê¸€ í°íŠ¸ ì„¤ì • í•¨ìˆ˜
def set_korean_font():
    import platform
    system_name = platform.system()
    if system_name == 'Windows':
        font_name = 'Malgun Gothic'
    elif system_name == 'Darwin':  # macOS
        font_name = 'AppleGothic'
    else:
        font_name = 'NanumGothic'  # ë¦¬ëˆ…ìŠ¤ ë“±

    plt.rc('font', family=font_name)
    plt.rcParams['axes.unicode_minus'] = False  # ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€

# ê¸°ë³¸ ê²½ë¡œ ì„¤ì •. ìŠ¬ë™ ìš”ì²­ì˜ 'challenge' í•„ë“œê°€ ìˆì„ ê²½ìš° í•´ë‹¹ ë‚´ìš©ì„ ì‘ë‹µí•´ Slack ìš”ì²­ì„ í™•ì¸
@app.route('/', methods=['POST'])
def hello_there():
    slack_event = json.loads(request.data)
    
    # Slackì—ì„œ ì˜¨ 'challenge' ìš”ì²­ì„ ì²˜ë¦¬í•˜ê³  ì‘ë‹µ
    if "challenge" in slack_event:
        return make_response(slack_event["challenge"], 200, {"Content-Type": "application/json"})
    
    return make_response("There are no slack request events", 404, {"X-Slack-No-Retry": 1})

# '/hello' Slash Command ì²˜ë¦¬ ë¼ìš°íŠ¸
@app.route('/hello', methods=['POST'])
def slash_hello():
    try:
        slack_event = request.form
        print(f"Received event: {slack_event}")  # ì´ë²¤íŠ¸ ë°ì´í„°ë¥¼ ì¶œë ¥í•˜ì—¬ í™•ì¸

        # Slackì—ì„œ ëª…ë ¹ì–´ê°€ ë°œìƒí•œ ì±„ë„ ID ì¶”ì¶œ
        channel_id = slack_event.get('channel_id')
        if not channel_id:
            print("Channel ID not found in the request.")
            return make_response("Channel ID not found", 400)
        print(f"Channel ID: {channel_id}")  # ì±„ë„ ID ì¶œë ¥

        # '/ì¸ì‚¬' ëª…ë ¹ì–´ë¥¼ ì¸ì‹í•˜ê³  Slack ë©”ì‹œì§€ë¥¼ ì „ì†¡
        command = slack_event.get('command')
        print(f"Command: {command}")

        if command == '/ì¸ì‚¬':
            try:
                # ë¸”ë¡ êµ¬ì„±
                blocks = [
                    {
                        "type": "section",
                        "text": {
                            "type": "mrkdwn",
                            "text": "*ì•ˆë…•í•˜ì„¸ìš”! ë°êµ´ë¥´~ ë°êµ´ì´ì—ìš”!* ğŸ¦\nì €ëŠ” íŒ€í”Œê³¼ ì¡°ë³„ê³¼ì œê°€ ë°êµ´ë°êµ´ ì˜ êµ´ëŸ¬ê°€ê²Œ ë„ì™€ì£¼ëŠ” ë˜‘ë˜‘í•œ ë„ìš°ë¯¸ëë‹ˆë‹¤! ë‹¤ì–‘í•œ ë¶„ì„ê³¼ ì¬ë¯¸ìˆëŠ” ê¸°ëŠ¥ë“¤ë¡œ ì—¬ëŸ¬ë¶„ì˜ í˜‘ì—…ì„ ë”ìš± ì›í™œí•˜ê²Œ ë§Œë“¤ì–´ë“œë ¤ìš”. ê¶ê¸ˆí•œ ì ì´ ìˆë‹¤ë©´ ì–¸ì œë“ ì§€ ì €ë¥¼ ë¶ˆëŸ¬ì£¼ì„¸ìš”!"
                        }
                    },
                    {
                        "type": "divider"
                    },
                    {
                        "type": "context",
                        "elements": [
                            {
                                "type": "mrkdwn",
                                "text": "ì €ëŠ” `/ë°œí™”ëŸ‰`, `/ë©”ì‹œì§€ìˆ˜`, `/ë°˜ì‘ìˆ˜`, `/ì£¼ì œìœ ì‚¬ë„` ê°™ì€ ì»¤ë§¨ë“œë¡œ ë‹¤ì–‘í•œ ë¶„ì„ì„ í•´ë“œë¦´ ìˆ˜ ìˆì–´ìš”!"
                            }
                        ]
                    }
                ]

                # í”„ë¡œí•„ ì´ë¯¸ì§€ URL ì„¤ì • (ì œê±°ë¨)

                response = client.chat_postMessage(
                    channel=channel_id,
                    blocks=blocks,
                    text="ì•ˆë…•í•˜ì„¸ìš”! ë°êµ´ì´ì—ìš”!"  # ë©”ì‹œì§€ ë¯¸ë¦¬ë³´ê¸°ì—ì„œ ë³´ì´ëŠ” í…ìŠ¤íŠ¸
                    # username="ë°êµ´ì´",  # ì œê±°
                    # icon_url=image_url,  # ì œê±°
                    # as_user=False  # ì œê±°
                )
                print(f"Message sent: {response}")
                return make_response("", 200)
            except SlackApiError as e:
                print(f"Slack API error: {e.response['error']}")
                error_message = f"Error sending message: {e.response['error']}"
                return make_response(error_message, 500)
            except Exception as e:
                print(f"Unexpected error in slash_hello: {e}")
                return make_response("Internal Server Error", 500)
        else:
            print("Command not recognized")
            return make_response("Command not recognized", 404)
    except Exception as e:
        print(f"Error processing the request: {e}")
        return make_response("Internal Server Error", 500)

# Slack íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ì½ê¸° ì‰¬ìš´ ì‹œê°„ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
def convert_timestamp_to_readable(ts):
    return datetime.utcfromtimestamp(float(ts)).strftime('%Y-%m-%d %H:%M:%S')

# ì±„ë„ì—ì„œ ì±„íŒ… ë¡œê·¸ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
def get_chatlog(channel_id, target='user'):
    try:
        chat_logs = []
        has_more = True
        next_cursor = None
        user_cache = {}  # ì‚¬ìš©ì ì •ë³´ ìºì‹±

        auth_response = client.auth_test()
        bot_user_id = auth_response['user_id']

        # ì±„ë„ì˜ ëª¨ë“  ë©”ì‹œì§€ë¥¼ ìˆ˜ì§‘
        while has_more:
            result = client.conversations_history(
                channel=channel_id,
                cursor=next_cursor,
                limit=200  # ìµœëŒ€ 200ê°œì˜ ë©”ì‹œì§€ë¥¼ í•œ ë²ˆì— ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŒ
            )

            messages = result["messages"]

            for message in messages:
                user_id = message.get('user')
                if not user_id:
                    continue  # ì‹œìŠ¤í…œ ë©”ì‹œì§€ ë“± ì‚¬ìš©ì ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° ê±´ë„ˆëœ€

                # ì‚¬ìš©ì ì •ë³´ ìºì‹±
                if user_id in user_cache:
                    username = user_cache[user_id]
                else:
                    user_info = client.users_info(user=user_id)
                    if not user_info['ok']:
                        continue
                    # display_nameì„ ë¨¼ì € ì‹œë„í•˜ê³ , ì—†ìœ¼ë©´ real_name, ì—†ìœ¼ë©´ nameì„ ì‚¬ìš©
                    username = user_info['user']['profile'].get('display_name') or user_info['user']['real_name'] or user_info['user']['name']
                    print(username)
                    user_cache[user_id] = username

                # íŠ¹ì • ì‚¬ìš©ìë§Œ í¬í•¨í• ì§€ ì„ íƒ
                if target == 'user' and user_id == bot_user_id:
                    continue
                elif target == 'bot' and user_id != bot_user_id:
                    continue

                chat_logs.append({
                    "user_id": user_id,
                    "username": username,
                    "text": message.get('text'),
                    "timestamp": message.get('ts'),
                    "reactions": message.get('reactions', [])
                })

            has_more = result.get('has_more', False)
            next_cursor = result.get('response_metadata', {}).get('next_cursor')

        # ì‹œê°„ìˆœ ì •ë ¬ (ì˜¤ë˜ëœ ë©”ì‹œì§€ë¶€í„°)
        chat_logs.reverse()

        return chat_logs

    except SlackApiError as e:
        print(f"Slack API error: {e.response['error']}")
        return None
    except Exception as e:
        print(f"Unexpected error: {str(e)}")
        return None

# ì‚¬ìš©ì ì°¸ì—¬ë„ ë¶„ì„ í•¨ìˆ˜
def analyze_participation(chat_logs, analysis_type):
    participation_scores = {}
    total_value = 0  # ì „ì²´ í•©ê³„

    for log in chat_logs:
        user_id = log['user_id']
        username = log['username']

        if user_id not in participation_scores:
            participation_scores[user_id] = {'username': username, 'text_length': 0, 'message_count': 0, 'reaction_count': 0}

        if analysis_type == 'speech_amount':
            text_length = len(log['text'])
            participation_scores[user_id]['text_length'] += text_length
            total_value += text_length

        elif analysis_type == 'message_count':
            participation_scores[user_id]['message_count'] += 1
            total_value += 1

        elif analysis_type == 'reaction_count':
            reactions = log.get('reactions', [])
            reaction_total = sum(reaction.get('count', 0) for reaction in reactions)
            participation_scores[user_id]['reaction_count'] += reaction_total
            total_value += reaction_total

    # ê° ë©¤ë²„ë³„ë¡œ ì „ì²´ ëŒ€ë¹„ ë¹„ìœ¨ ë° ê°’ì„ ì €ì¥
    for user_id, scores in participation_scores.items():
        if analysis_type == 'speech_amount':
            value = scores['text_length']
            scores['percentage'] = (value / total_value) * 100 if total_value > 0 else 0
            scores['value'] = value
        elif analysis_type == 'message_count':
            value = scores['message_count']
            scores['percentage'] = (value / total_value) * 100 if total_value > 0 else 0
            scores['value'] = value
        elif analysis_type == 'reaction_count':
            value = scores['reaction_count']
            scores['percentage'] = (value / total_value) * 100 if total_value > 0 else 0
            scores['value'] = value

    return participation_scores

# ì°¸ì—¬ë„ ì°¨íŠ¸ ìƒì„± í•¨ìˆ˜
def create_participation_chart(participation_scores, analysis_type):
    set_korean_font()  # í•œê¸€ í°íŠ¸ ì„¤ì •

    # ì°¸ì—¬ë„ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
    sorted_participation = sorted(participation_scores.items(), key=lambda x: x[1]['value'], reverse=True)

    usernames = [scores['username'] for user_id, scores in sorted_participation]
    values = [scores['value'] for user_id, scores in sorted_participation]

    if analysis_type == 'speech_amount':
        title = 'ë°œí™”ëŸ‰ ë¹„ìœ¨'
    elif analysis_type == 'message_count':
        title = 'ë©”ì‹œì§€ ìˆ˜ ë¹„ìœ¨'
    elif analysis_type == 'reaction_count':
        title = 'ë°˜ì‘ ìˆ˜ ë¹„ìœ¨'
    else:
        title = 'ì°¸ì—¬ë„ ë¶„ì„ ê²°ê³¼'

    total = sum(values)
    autopct = lambda p: '{:.1f}%\n({:.0f})'.format(p, (p * total / 100))

    # ìƒ‰ìƒ ë¦¬ìŠ¤íŠ¸ ì •ì˜ (í•„ìš”ì— ë”°ë¼ ì¶”ê°€)
    colors = ['gold', 'lightskyblue', 'lightcoral']

    # ê°€ì¥ ì²« ë²ˆì§¸ ìš”ì†Œ(ê°€ì¥ í° ê°’)ì—ë§Œ 0.1ì„ í• ë‹¹í•˜ê³ , ë‚˜ë¨¸ì§€ëŠ” 0ìœ¼ë¡œ ì„¤ì •
    explode = [0.1] + [0] * (len(values) - 1)

    plt.figure(figsize=(8, 6))
    patches, texts, autotexts = plt.pie(
        values, 
        labels=usernames, 
        autopct=autopct, 
        startangle=90, 
        counterclock=False, 
        colors=colors, 
        shadow=True,
        explode=explode
    )

    # ë²”ë¡€ ì¶”ê°€
    plt.legend(patches, usernames, loc="best")

    # ì¶• ê· ë“± ì„¤ì • (ì›í˜• ìœ ì§€)
    plt.axis('equal')

    # ì œëª© ì„¤ì •: ì¢Œì¸¡ ìƒë‹¨ ìœ„ì¹˜, í°íŠ¸ í¬ê¸° ì¦ê°€
    plt.title(title, loc='left', fontsize=20)

    # ë ˆì´ì•„ì›ƒ ì¡°ì •
    plt.tight_layout()

    # ì´ë¯¸ì§€ ë²„í¼ë¡œ ì €ì¥
    img_buf = io.BytesIO()
    plt.savefig(img_buf, format='png')
    img_buf.seek(0)
    plt.close()

    return img_buf

# ì°¸ì—¬ë„ ë¶„ì„ ê²°ê³¼ë¥¼ ìœ„í•œ ë¸”ë¡ ìƒì„± í•¨ìˆ˜
def format_participation_blocks(participation_scores, analysis_type):
    # ì°¸ì—¬ë„ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
    sorted_participation = sorted(participation_scores.items(), key=lambda x: x[1]['value'], reverse=True)
    top_user_username = sorted_participation[0][1]['username']

    # ì´í•©ê³„ ê³„ì‚°
    total_value = sum(scores['value'] for user_id, scores in sorted_participation)
    average_value = total_value / len(sorted_participation) if sorted_participation else 0
    values = [scores['value'] for user_id, scores in sorted_participation]
    max_value = max(values) if values else 0
    min_value = min(values) if values else 0

    blocks = [
        {
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": f"*ì°¸ì—¬ë„ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤!* :sparkles:"
            }
        },
        {"type": "divider"},
        {
            "type": "section",
            "fields": [
                {
                    "type": "mrkdwn",
                    "text": f"*ì´í•©ê³„:* {total_value}"
                },
                {
                    "type": "mrkdwn",
                    "text": f"*í‰ê· :* {average_value:.2f}"
                },
                {
                    "type": "mrkdwn",
                    "text": f"*ìµœëŒ€ê°’:* {max_value}"
                },
                {
                    "type": "mrkdwn",
                    "text": f"*ìµœì†Œê°’:* {min_value}"
                }
            ]
        },
        {"type": "divider"},
        {
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": f":crown: ì°¸ì—¬ë„ MVPëŠ” *{top_user_username}* ë‹˜ ì…ë‹ˆë‹¤! ì •ë§ ëŒ€ë‹¨í•´ìš”!"
            }
        },
        {"type": "divider"}
    ]

    # ê° ë©¤ë²„ë³„ ê²°ê³¼ ì¶”ê°€
    for user_id, scores in sorted_participation:
        percentage = scores.get('percentage', 0)
        value = scores['value']
        if analysis_type == 'speech_amount':
            text = f"*{scores['username']}* ë‹˜: {value} ê¸€ì ({percentage:.1f}%)"
        elif analysis_type == 'message_count':
            text = f"*{scores['username']}* ë‹˜: {value} ë©”ì‹œì§€ ({percentage:.1f}%)"
        elif analysis_type == 'reaction_count':
            text = f"*{scores['username']}* ë‹˜: {value} ë°˜ì‘ ({percentage:.1f}%)"

        blocks.append(
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": text
                }
            }
        )

    return blocks

# ì°¸ì—¬ë„ ë¶„ì„ ì‹¤í–‰ í•¨ìˆ˜
def handle_participation_analysis(channel_id, analysis_type):
    try:
        chat_logs = get_chatlog(channel_id)
        if not chat_logs:
            client.chat_postMessage(
                channel=channel_id,
                text="ì•—! ì±„íŒ… ë¡œê·¸ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”."
            )
            return

        participation_scores = analyze_participation(chat_logs, analysis_type)
        img_buf = create_participation_chart(participation_scores, analysis_type)
        analysis_titles = {
            'speech_amount': 'ë°œí™”ëŸ‰ ë¶„ì„ ê²°ê³¼',
            'message_count': 'ë©”ì‹œì§€ ìˆ˜ ë¶„ì„ ê²°ê³¼',
            'reaction_count': 'ë°˜ì‘ ìˆ˜ ë¶„ì„ ê²°ê³¼'
        }

        # ê²°ê³¼ ì´ë¯¸ì§€ ì—…ë¡œë“œ
        upload_response = client.files_upload_v2(
            channel=channel_id,
            file=img_buf,
            filename='participation_analysis.png',
            title=analysis_titles.get(analysis_type, 'ì°¸ì—¬ë„ ë¶„ì„ ê²°ê³¼')
        )

        blocks = format_participation_blocks(participation_scores, analysis_type)

        client.chat_postMessage(
                channel=channel_id,
                blocks=blocks,
                text="ì°¸ì—¬ë„ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤!"
        )
        
        # if upload_response['ok']:
        #     # ì—…ë¡œë“œëœ íŒŒì¼ì˜ ì •ë³´
        #     file_info = upload_response['file']
        #     file_url = file_info.get('permalink_public')  # ê³µê°œ URL í™•ë³´

        #     if not file_url:
        #         # permalink_publicì´ ì—†ëŠ” ê²½ìš°
        #         client.chat_postMessage(
        #             channel=channel_id,
        #             text="ì•—! ì´ë¯¸ì§€ë¥¼ ê³µê°œì ìœ¼ë¡œ ê³µìœ í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”."
        #         )
        #         return

        #     # 2. ë¶„ì„ ê²°ê³¼ ë¸”ë¡ ìƒì„±
        #     blocks = format_participation_blocks(participation_scores, analysis_type)

        #     blocks.append(
        #         {
        #             "type": "image",
        #             "image_url": file_url,
        #             "alt_text": "ì°¸ì—¬ë„ ë¶„ì„ ê²°ê³¼"
        #         }
        #     )

        #     # 3. ë¶„ì„ ê²°ê³¼ ë©”ì‹œì§€ ì „ì†¡
        #     client.chat_postMessage(
        #         channel=channel_id,
        #         blocks=blocks,
        #         text="ì°¸ì—¬ë„ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤!"  # ê¸°ë³¸ í…ìŠ¤íŠ¸ ì¶”ê°€
        #     )
        # else:
        #     client.chat_postMessage(
        #         channel=channel_id,
        #         text="ì•—! ê²°ê³¼ë¥¼ ì—…ë¡œë“œí•˜ëŠ” ì¤‘ì— ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”."
        #     )
    except SlackApiError as e:
        print(f"Slack API error: {e.response['error']}")
        client.chat_postMessage(
            channel=channel_id,
            text="ì•—! Slack API ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”."
        )
    except Exception as e:
        print(f"Error in handle_participation_analysis: {e}")
        client.chat_postMessage(
            channel=channel_id,
            text="ì•—! ì°¸ì—¬ë„ ë¶„ì„ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”."
        )

# ì°¸ì—¬ë„ ë¶„ì„ ëª…ë ¹ì–´ ì²˜ë¦¬ ë¼ìš°íŠ¸ (ë°œí™”ëŸ‰)
@app.route('/participation_speech', methods=['POST'])
def participation_speech():
    slack_event = request.form.copy()
    channel_id = slack_event.get('channel_id')

    threading.Thread(target=handle_participation_analysis, args=(channel_id, 'speech_amount')).start()

    return make_response("ë°œí™”ëŸ‰ ì°¸ì—¬ë„ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.", 200)

# ì°¸ì—¬ë„ ë¶„ì„ ëª…ë ¹ì–´ ì²˜ë¦¬ ë¼ìš°íŠ¸ (ë©”ì‹œì§€ ìˆ˜)
@app.route('/participation_message', methods=['POST'])
def participation_message():
    slack_event = request.form.copy()
    channel_id = slack_event.get('channel_id')

    threading.Thread(target=handle_participation_analysis, args=(channel_id, 'message_count')).start()

    return make_response("ë©”ì‹œì§€ ìˆ˜ ì°¸ì—¬ë„ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.", 200)

# ì°¸ì—¬ë„ ë¶„ì„ ëª…ë ¹ì–´ ì²˜ë¦¬ ë¼ìš°íŠ¸ (ë°˜ì‘ ìˆ˜)
@app.route('/participation_reaction', methods=['POST'])
def participation_reaction():
    slack_event = request.form.copy()
    channel_id = slack_event.get('channel_id')

    threading.Thread(target=handle_participation_analysis, args=(channel_id, 'reaction_count')).start()

    return make_response("ë°˜ì‘ ìˆ˜ ì°¸ì—¬ë„ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.", 200)

# ì±„íŒ… ë¡œê·¸ ì „ì²˜ë¦¬ í•¨ìˆ˜
def preprocess_chat_logs(chat_logs):
    preprocessed_text = []
    indexed_chat_logs = []
    texts = []

    for idx, log in enumerate(chat_logs):
        user_id = log['user_id']
        username = log['username']
        text = log['text']

        # ì¸ë±ìŠ¤ì™€ ì‚¬ìš©ìëª… í¬í•¨í•œ í…ìŠ¤íŠ¸ ìƒì„±
        preprocessed_text.append(f"{idx}: <@{username}>: {text}")

        # ì¸ë±ìŠ¤ê°€ í¬í•¨ëœ ì±„íŒ… ë¡œê·¸ ìƒì„±
        indexed_chat_logs.append({
            'index': idx,
            'user_id': user_id,
            'username': username,
            'text': text
        })

        texts.append(text)

    return "\n".join(preprocessed_text), indexed_chat_logs, texts

# LLMì„ ì‚¬ìš©í•˜ì—¬ ì£¼ì œ ì¶”ì¶œ í•¨ìˆ˜
def extract_topic(full_meeting_text):
    prompt_text = """
    ë‹¹ì‹ ì€ ì£¼ì œ ì¶”ì¶œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

    ë‹¤ìŒì€ íšŒì˜ì˜ ì „ì²´ ëŒ€í™” ë‚´ìš©ì…ë‹ˆë‹¤:
    '{full_meeting_text}'

    ì´ íšŒì˜ì˜ ì£¼ìš” ì£¼ì œë¥¼ í•˜ë‚˜ì˜ ëª…ì‚¬êµ¬ë¡œ 10ì ì´ë‚´ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.
    ì˜ˆì‹œ: 'ì œí’ˆ ì¶œì‹œ ê³„íš', 'ì˜ˆì‚° ì ˆê° ë°©ì•ˆ'
    ì‘ë‹µì€ ì˜¤ì§ ì£¼ì œë§Œ ì‘ì„±í•˜ê³ , ë‹¤ë¥¸ ë¶ˆí•„ìš”í•œ ë§ì€ í•˜ì§€ ë§ˆì„¸ìš”.
    """

    prompt = prompt_text.format(full_meeting_text=full_meeting_text)

    try:
        topic = watsonx_llm.invoke(prompt)
        topic = topic.strip()
        topic = topic.split('|')[0]  # '|' ë¬¸ìê°€ ìˆë‹¤ë©´ ê·¸ ì•ë¶€ë¶„ë§Œ ì‚¬ìš©

        print(f"LLM ì‘ë‹µ: {topic}")
        return topic
    except Exception as e:
        print(f"Error extracting topic: {e}")
        return "ì£¼ì œ ì¶”ì¶œ ì‹¤íŒ¨"

# ì„ë² ë”© ìƒì„± í•¨ìˆ˜
def get_embeddings(text_list):
    embeddings = embedding_model.embed_documents(texts=text_list)
    embeddings = np.array(embeddings)
    return embeddings

# ìœ ì‚¬ë„ ê³„ì‚° í•¨ìˆ˜
def calculate_similarity(embedding1, embedding2):
    embedding1 = np.array(embedding1).reshape(1, -1)
    embedding2 = np.array(embedding2).reshape(1, -1)
    return cosine_similarity(embedding1, embedding2)[0][0]

# ìœ ì‚¬ë„ ì ìˆ˜ í†µê³„ì¹˜ ê³„ì‚° í•¨ìˆ˜
def calculate_similarity_statistics(similarity_scores):
    max_score = np.max(similarity_scores)
    min_score = np.min(similarity_scores)
    mean_score = np.mean(similarity_scores)
    median_score = np.median(similarity_scores)
    std_dev = np.std(similarity_scores)
    percentiles = np.percentile(similarity_scores, [25, 50, 75, 90, 95])

    print("ìœ ì‚¬ë„ ì ìˆ˜ í†µê³„ì¹˜:")
    print(f"ìµœëŒ€ê°’: {max_score:.4f}")
    print(f"ìµœì†Œê°’: {min_score:.4f}")
    print(f"í‰ê· ê°’: {mean_score:.4f}")
    print(f"ì¤‘ì•™ê°’: {median_score:.4f}")
    print(f"í‘œì¤€í¸ì°¨: {std_dev:.4f}")
    print(f"ë°±ë¶„ìœ„ìˆ˜ (25%, 50%, 75%, 90%, 95%): {percentiles}")

    return {
        'max': max_score,
        'min': min_score,
        'mean': mean_score,
        'median': median_score,
        'std_dev': std_dev,
        'percentiles': percentiles
    }

# ìœ ì‚¬ë„ ì ìˆ˜ ë¶„í¬ ì‹œê°í™” í•¨ìˆ˜
def plot_similarity_distribution(similarity_scores, threshold):
    set_korean_font()  # í•œê¸€ í°íŠ¸ ì„¤ì •

    plt.figure(figsize=(10, 6))
    sns.histplot(similarity_scores, bins=30, kde=True, color='skyblue')
    plt.title('ìœ ì‚¬ë„ ì ìˆ˜ ë¶„í¬', loc='left', fontsize=20)
    plt.xlabel('ìœ ì‚¬ë„ ì ìˆ˜')
    plt.ylabel('ë¹ˆë„ìˆ˜')

    # threshold ìœ„ì¹˜ì— ì„¸ë¡œì„  ì¶”ê°€
    plt.axvline(x=threshold, color="red", linestyle="--", label=f"Threshold ({threshold:.2f})")

    img_buf = io.BytesIO()
    plt.savefig(img_buf, format='png')
    img_buf.seek(0)
    plt.close()

    return img_buf

# í´ëŸ¬ìŠ¤í„°ë³„ ìµœì†Œê°’ê³¼ ìµœëŒ€ê°’ ê³„ì‚° í•¨ìˆ˜
def get_cluster_min_max(similarity_scores, labels):
    cluster_0_scores = similarity_scores[labels == 0]
    cluster_1_scores = similarity_scores[labels == 1]

    cluster_0_min = np.min(cluster_0_scores)
    cluster_0_max = np.max(cluster_0_scores)
    cluster_1_min = np.min(cluster_1_scores)
    cluster_1_max = np.max(cluster_1_scores)

    return {
        'cluster_0': {'min': cluster_0_min, 'max': cluster_0_max},
        'cluster_1': {'min': cluster_1_min, 'max': cluster_1_max}
    }

# ì„ê³„ê°’ ê³„ì‚° í•¨ìˆ˜
def determine_threshold_with_cluster_extremes(cluster_min_max, kmeans):
    # í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬ì  í™•ì¸
    cluster_0_centroid = kmeans.cluster_centers_[0][0]
    cluster_1_centroid = kmeans.cluster_centers_[1][0]

    if cluster_0_centroid > cluster_1_centroid:
        topic_cluster = 0
        non_topic_cluster = 1
    else:
        topic_cluster = 1
        non_topic_cluster = 0

    # ì£¼ì œ ê´€ë ¨ í´ëŸ¬ìŠ¤í„°ì˜ ìµœì†Œê°’ê³¼ ë¹„ê´€ë ¨ í´ëŸ¬ìŠ¤í„°ì˜ ìµœëŒ€ê°’
    topic_cluster_min = cluster_min_max[f'cluster_{topic_cluster}']['min']
    non_topic_cluster_max = cluster_min_max[f'cluster_{non_topic_cluster}']['max']

    # ì„ê³„ê°’ ê³„ì‚°
    threshold = (topic_cluster_min + non_topic_cluster_max) / 2
    print(f"ì£¼ì œ ê´€ë ¨ í´ëŸ¬ìŠ¤í„° ìµœì†Œê°’: {topic_cluster_min:.4f}")
    print(f"ë¹„ê´€ë ¨ í´ëŸ¬ìŠ¤í„° ìµœëŒ€ê°’: {non_topic_cluster_max:.4f}")
    print(f"ì„¤ì •ëœ ì„ê³„ê°’ (ë‘ ê°’ì˜ ì¤‘ê°„ê°’): {threshold:.4f}")

    return threshold, topic_cluster

# ì£¼ì œ ê´€ë ¨ ë°œì–¸ ë¹„ìœ¨ ê³„ì‚° í•¨ìˆ˜
def calculate_high_similarity_ratio_with_threshold(indexed_chat_logs, similarity_scores, threshold):
    user_high_similarity = {}

    for i, log in enumerate(indexed_chat_logs):
        user_id = log['user_id']
        username = log['username']
        similarity_score = similarity_scores[i]

        if user_id not in user_high_similarity:
            user_high_similarity[user_id] = {'username': username, 'high_similarity_count': 0, 'message_count': 0}
        if similarity_score >= threshold:
            user_high_similarity[user_id]['high_similarity_count'] += 1
        user_high_similarity[user_id]['message_count'] += 1

    # ë¹„ìœ¨ ê³„ì‚°
    for user_id in user_high_similarity:
        user_high_similarity[user_id]['high_similarity_ratio'] = (
            user_high_similarity[user_id]['high_similarity_count'] / user_high_similarity[user_id]['message_count']
        )

    return user_high_similarity

# ì£¼ì œ ê´€ë ¨ ë°œì–¸ ë¹„ìœ¨ ì°¨íŠ¸ ìƒì„± í•¨ìˆ˜
def create_high_similarity_chart(sorted_high_similarity_scores):
    set_korean_font()  # í•œê¸€ í°íŠ¸ ì„¤ì •

    # sorted_high_similarity_scoresëŠ” ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ íŠœí”Œ (user_id, info_dict)
    usernames = [info['username'] for _, info in sorted_high_similarity_scores]
    high_similarity_ratios = [info['high_similarity_ratio'] for _, info in sorted_high_similarity_scores]

    # ìƒ‰ìƒ ë¦¬ìŠ¤íŠ¸
    colors = ['gold', 'lightcoral', 'lightskyblue']

    # ë°” ì°¨íŠ¸ ìƒì„±
    fig, ax = plt.subplots(figsize=(8, 6))
    ax.bar(usernames, high_similarity_ratios, color=colors)
    ax.set_title('ì£¼ì œ ê´€ë ¨ ë°œì–¸ ë¹„ìœ¨', loc='left', fontsize=20)
    ax.set_ylabel('ë¹„ìœ¨')

    plt.tight_layout()

    img_buf = io.BytesIO()
    plt.savefig(img_buf, format='png')
    img_buf.seek(0)
    plt.close()

    return img_buf

# ì£¼ì œ ìœ ì‚¬ë„ ë¶„ì„ ì‹¤í–‰ í•¨ìˆ˜
def perform_topic_relevance_analysis(chat_logs):
    # ì±„íŒ… ë¡œê·¸ ì „ì²˜ë¦¬
    full_meeting_text, indexed_chat_logs, texts = preprocess_chat_logs(chat_logs)

    # ì£¼ì œ ì¶”ì¶œ
    extracted_topic = extract_topic(full_meeting_text)
    print(f"ì¶”ì¶œëœ ì£¼ì œ: {extracted_topic}")

    # ì„ë² ë”© ê³„ì‚°
    topic_embedding = get_embeddings([extracted_topic])[0]
    text_embeddings = get_embeddings(texts)

    # ìœ ì‚¬ë„ ì ìˆ˜ ê³„ì‚°
    similarity_scores = []
    for text_embedding in text_embeddings:
        similarity = calculate_similarity(topic_embedding, text_embedding)
        similarity_scores.append(similarity)
    similarity_scores = np.array(similarity_scores)

    # í†µê³„ì¹˜ ê³„ì‚°
    statistics = calculate_similarity_statistics(similarity_scores)

    # K-í‰ê·  í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰
    scores_reshaped = similarity_scores.reshape(-1, 1)
    kmeans = KMeans(n_clusters=2, random_state=0).fit(scores_reshaped)
    labels = kmeans.labels_

    # í´ëŸ¬ìŠ¤í„°ë³„ ìµœì†Œê°’ê³¼ ìµœëŒ€ê°’ ê³„ì‚°
    cluster_min_max = get_cluster_min_max(similarity_scores, labels)

    # ì„ê³„ê°’ ê³„ì‚°
    threshold, topic_cluster = determine_threshold_with_cluster_extremes(cluster_min_max, kmeans)

    # ì£¼ì œ ê´€ë ¨ ë°œì–¸ ë¹„ìœ¨ ê³„ì‚°
    high_similarity_scores = calculate_high_similarity_ratio_with_threshold(
        indexed_chat_logs, similarity_scores, threshold
    )

    # ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    sorted_high_similarity_scores = sorted(high_similarity_scores.items(), key=lambda x: x[1]['high_similarity_ratio'], reverse=True)

    # MVP ì„ ì • (ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆì§€ ì•Šì€ì§€ í™•ì¸)
    if sorted_high_similarity_scores:
        mvp_user_id, mvp_info = sorted_high_similarity_scores[0]
        mvp_user = mvp_info['username']
    else:
        mvp_user = "ì—†ìŒ"

    # ì£¼ì œ ê´€ë ¨ ë°œì–¸ ë¹„ìœ¨ ì°¨íŠ¸ ìƒì„±
    chart_buf = create_high_similarity_chart(sorted_high_similarity_scores)

    # ìœ ì‚¬ë„ ë¶„í¬
    similarity_distribution = plot_similarity_distribution(similarity_scores, threshold)

    return sorted_high_similarity_scores, chart_buf, extracted_topic, statistics, similarity_distribution, threshold, mvp_user

# ì£¼ì œ ìœ ì‚¬ë„ ë¶„ì„ ëª…ë ¹ì–´ ì²˜ë¦¬ ë¼ìš°íŠ¸
@app.route('/topic_relevance', methods=['POST'])
def topic_relevance():
    slack_event = request.form.copy()
    channel_id = slack_event.get('channel_id')
    user_id = slack_event.get('user_id')

    threading.Thread(target=handle_topic_relevance, args=(channel_id, user_id)).start()

    return make_response("ì£¼ì œ ìœ ì‚¬ë„ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.", 200)

# ì£¼ì œ ìœ ì‚¬ë„ ë¶„ì„ í•¨ìˆ˜
def handle_topic_relevance(channel_id, user_id):
    try:
        # ì±„íŒ… ë¡œê·¸ ê°€ì ¸ì˜¤ê¸°
        chat_logs = get_chatlog(channel_id)
        if not chat_logs:
            client.chat_postMessage(
                channel=channel_id,
                text="ì•—! ì±„íŒ… ë¡œê·¸ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”."
            )
            return

        MODEL_NAME = 'llama3-70b'

        watsonx_llm = WatsonxLLM(
            model_id=MODEL_ID_list[MODEL_NAME],
            url="https://us-south.ml.cloud.ibm.com",
            project_id=PROJECT_ID,
            params=parameters,
        )

        # ì£¼ì œ ìœ ì‚¬ë„ ë¶„ì„ ì‹¤í–‰
        (
            sorted_high_similarity_scores, topic_chart_buf, extracted_topic,
            statistics, similarity_distribution, threshold, mvp_user
        ) = perform_topic_relevance_analysis(chat_logs)

        # ë¸”ë¡ ìƒì„± í•¨ìˆ˜ í˜¸ì¶œ
        blocks = format_topic_relevance_blocks(extracted_topic, statistics, threshold, mvp_user)

        client.chat_postMessage(
            channel=channel_id,
            blocks=blocks,
            text="ì£¼ì œ ìœ ì‚¬ë„ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤!"
        )

        # ìœ ì‚¬ë„ ë¶„í¬ ì°¨íŠ¸ ì´ë¯¸ì§€ ì—…ë¡œë“œ
        dsitribution_chart_upload = client.files_upload_v2(
            channel=channel_id,
            file=similarity_distribution,
            filename='similarity_distribution.png',
            title='ìœ ì‚¬ë„ ë¶„í¬ ì‹œê°í™”'
        )

        # ê²°ê³¼ ì´ë¯¸ì§€ ì—…ë¡œë“œ
        topic_chart_upload = client.files_upload_v2(
            channel=channel_id,
            file=topic_chart_buf,
            filename='topic_relevance_analysis.png',
            title='ì£¼ì œ ìœ ì‚¬ë„ ë¶„ì„ ê²°ê³¼'
        )

        # if topic_chart_upload['ok']:
        #     topic_file_info = topic_chart_upload['file']
        #     topic_file_url = topic_file_info.get('permalink_public')

        #     # ë¸”ë¡ ìƒì„± í•¨ìˆ˜ í˜¸ì¶œ
        #     blocks = format_topic_relevance_blocks(extracted_topic, statistics, topic_file_url)

        #     client.chat_postMessage(
        #         channel=channel_id,
        #         blocks=blocks,
        #         text="ì£¼ì œ ìœ ì‚¬ë„ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤!"
        #     )
        # else:
        #     client.chat_postMessage(
        #         channel=channel_id,
        #         text="ì•—! ê²°ê³¼ë¥¼ ì—…ë¡œë“œí•˜ëŠ” ì¤‘ì— ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”."
        #     )
    except Exception as e:
        print(f"Error in handle_topic_relevance: {e}")
        client.chat_postMessage(
            channel=channel_id,
            text="ì•—! ì£¼ì œ ìœ ì‚¬ë„ ë¶„ì„ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”."
        )


def format_topic_relevance_blocks(extracted_topic, statistics, threshold, mvp_user):
    statistics_block = {
        "type": "section",
        "fields": [
            {
                "type": "mrkdwn",
                "text": f"*ìµœëŒ€ê°’:* {statistics['max']:.4f}"
            },
            {
                "type": "mrkdwn",
                "text": f"*ìµœì†Œê°’:* {statistics['min']:.4f}"
            },
            {
                "type": "mrkdwn",
                "text": f"*í‰ê· ê°’:* {statistics['mean']:.4f}"
            },
            {
                "type": "mrkdwn",
                "text": f"*ì¤‘ì•™ê°’:* {statistics['median']:.4f}"
            },
            {
                "type": "mrkdwn",
                "text": f"*í‘œì¤€í¸ì°¨:* {statistics['std_dev']:.4f}"
            },
            {
                "type": "mrkdwn",
                "text": f"*í´ëŸ¬ìŠ¤í„° ì„ê³„ê°’:* {threshold:.4f}"
            }
        ]
    }

    # MVP ë©”ì‹œì§€
    mvp_block = {
        "type": "section",
        "text": {
            "type": "mrkdwn",
            "text": f"*:crown: ì°¸ì—¬ë„ MVPëŠ” *{mvp_user}* ë‹˜ì…ë‹ˆë‹¤! ì •ë§ ëŒ€ë‹¨í•´ìš”! :tada:"
        }
    }

    blocks = [
        {
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": f"*ì£¼ì œ ìœ ì‚¬ë„ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤!* :sparkles:\nì¶”ì¶œëœ ì£¼ì œ: *{extracted_topic}*"
            }
        },
        statistics_block,
        {"type": "divider"},
        mvp_block
        # {
        #     "type": "image",
        #     "image_url": topic_file_url,
        #     "alt_text": "ì£¼ì œ ìœ ì‚¬ë„ ë¶„ì„ ê·¸ë˜í”„"
        # }
    ]
    return blocks



# ê°œë³„ ë°œì–¸ í‰ê°€ í•¨ìˆ˜
def evaluate_single_utterance_with_llm(log):
    utterance_text = f"{log['index']}: <@{log['username']}>: {log['text']}"

    prompt_text = f"""
    ë°œì–¸: '{utterance_text}'

    ìœ„ ë°œì–¸ì— ëŒ€í•´ ë‹¤ìŒ ë„¤ ê°€ì§€ ê¸°ì¤€ìœ¼ë¡œ 1~5ì  ì²™ë„ë¡œ í‰ê°€í•˜ì„¸ìš”:
    1. í† ë¡  ìœ ë„ ë° ë‹¤ë¥¸ íŒ€ì› ë°œì–¸ ì´‰ì§„
    2. íšŒì˜ ë°©í–¥ ì„¤ì • ë° ê²°ë¡  ë„ì¶œ ê¸°ì—¬
    3. íšŒì˜ ëª©í‘œ ë‹¬ì„±ì— ëŒ€í•œ ê¸°ì—¬
    4. í˜‘ì—… ì´‰ì§„ ë° ì˜ê²¬ ì°¨ì´ ì¢íˆê¸°

    í˜•ì‹:
    [í† ë¡  ìœ ë„ ì ìˆ˜, íšŒì˜ ë°©í–¥ ì ìˆ˜, ëª©í‘œ ë‹¬ì„± ì ìˆ˜, í˜‘ì—… ì´‰ì§„ ì ìˆ˜]

    ì‘ë‹µì€ ìœ„ì˜ í˜•ì‹ìœ¼ë¡œë§Œ ì‘ì„±í•˜ê³ , ì¶”ê°€ ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”.
    """

    prompt = prompt_text

    try:
        response = watsonx_llm.invoke(prompt)
        print(f"ì¸ë±ìŠ¤ {log['index']}ì˜ ì‘ë‹µ:\n{response}\n")
        pattern = re.compile(r'\[(\d+),\s*(\d+),\s*(\d+),\s*(\d+)\]')
        match = pattern.search(response.strip())
        if match:
            scores = [int(match.group(i)) for i in range(1, 5)]
            evaluation_result = {
                'index': log['index'],
                'user_id': log['user_id'],
                'username': log['username'],
                'discussion': scores[0],
                'direction': scores[1],
                'goal': scores[2],
                'collaboration': scores[3]
            }
            return evaluation_result
        else:
            print(f"ì‘ë‹µì—ì„œ ì ìˆ˜ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì¸ë±ìŠ¤ {log['index']}")
            return None
    except Exception as e:
        print(f"LLM í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ì¸ë±ìŠ¤ {log['index']}): {e}")
        return None

# ì‚¬ìš©ìë³„ ê¸°ì—¬ë„ ì ìˆ˜ ì§‘ê³„ í•¨ìˆ˜
def aggregate_contribution_scores(indexed_chat_logs, evaluation_results):
    contribution_scores = {}
    for eval_result in evaluation_results:
        user_id = eval_result['user_id']
        username = eval_result['username']
        if user_id not in contribution_scores:
            contribution_scores[user_id] = {
                'username': username,
                'discussion': 0,
                'direction': 0,
                'goal': 0,
                'collaboration': 0
            }
        contribution_scores[user_id]['discussion'] += eval_result['discussion']
        contribution_scores[user_id]['direction'] += eval_result['direction']
        contribution_scores[user_id]['goal'] += eval_result['goal']
        contribution_scores[user_id]['collaboration'] += eval_result['collaboration']
    return contribution_scores

# ê¸°ì—¬ë„ ì°¨íŠ¸ ìƒì„± í•¨ìˆ˜
def create_contribution_chart(contribution_scores):
    set_korean_font()  # í•œê¸€ í°íŠ¸ ì„¤ì •

    usernames = [scores['username'] for scores in contribution_scores.values()]
    discussion_scores = [scores['discussion'] for scores in contribution_scores.values()]
    direction_scores = [scores['direction'] for scores in contribution_scores.values()]
    goal_scores = [scores['goal'] for scores in contribution_scores.values()]
    collaboration_scores = [scores['collaboration'] for scores in contribution_scores.values()]

    x = np.arange(len(usernames))
    width = 0.2

    colors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral']

    plt.figure(figsize=(12, 6))
    plt.bar(x - width*1.5, discussion_scores, width=width, label='í† ë¡  ìœ ë„', color=colors[0])
    plt.bar(x - width*0.5, direction_scores, width=width, label='íšŒì˜ ë°©í–¥', color=colors[1])
    plt.bar(x + width*0.5, goal_scores, width=width, label='ëª©í‘œ ë‹¬ì„±', color=colors[2])
    plt.bar(x + width*1.5, collaboration_scores, width=width, label='í˜‘ì—… ì´‰ì§„', color=colors[3])

    plt.xticks(x, usernames)
    plt.xlabel('ì‚¬ìš©ì')
    plt.ylabel('ì ìˆ˜ í•©ê³„')
    plt.title('ì‚¬ìš©ìë³„ íšŒì˜ ê¸°ì—¬ë„ ë¶„ì„', loc='left', fontsize=20)
    plt.legend()
    plt.tight_layout()

    img_buf = io.BytesIO()
    plt.savefig(img_buf, format='png')
    img_buf.seek(0)
    plt.close()

    return img_buf

# íšŒì˜ ê¸°ì—¬ë„ ë¶„ì„ ì‹¤í–‰ í•¨ìˆ˜
def perform_contribution_analysis(chat_logs):
    # ì±„íŒ… ë¡œê·¸ ì „ì²˜ë¦¬
    _, indexed_chat_logs, _ = preprocess_chat_logs(chat_logs)

    all_evaluation_results = []
    for log in indexed_chat_logs:
        evaluation_result = evaluate_single_utterance_with_llm(log)
        if evaluation_result:
            all_evaluation_results.append(evaluation_result)
        else:
            continue

    # ì‚¬ìš©ìë³„ ê¸°ì—¬ë„ ì ìˆ˜ ì§‘ê³„
    contribution_scores = aggregate_contribution_scores(indexed_chat_logs, all_evaluation_results)

    # ê¸°ì—¬ë„ ì°¨íŠ¸ ìƒì„±
    chart_buf = create_contribution_chart(contribution_scores)

    return contribution_scores, chart_buf

# íšŒì˜ ê¸°ì—¬ë„ ë¶„ì„ ëª…ë ¹ì–´ ì²˜ë¦¬ ë¼ìš°íŠ¸
@app.route('/contribution_analysis', methods=['POST'])
def contribution_analysis():
    slack_event = request.form.copy()
    channel_id = slack_event.get('channel_id')
    user_id = slack_event.get('user_id')

    threading.Thread(target=handle_contribution_analysis, args=(channel_id, user_id)).start()

    return make_response("íšŒì˜ ê¸°ì—¬ë„ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.", 200)

# íšŒì˜ ì§„í–‰ ê¸°ì—¬ë„ ë¶„ì„ í•¨ìˆ˜
def handle_contribution_analysis(channel_id, user_id):
    try:
        # ì±„íŒ… ë¡œê·¸ ê°€ì ¸ì˜¤ê¸°
        chat_logs = get_chatlog(channel_id)
        if not chat_logs:
            client.chat_postMessage(
                channel=channel_id,
                text="ì•—! ì±„íŒ… ë¡œê·¸ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”."
            )
            return

        MODEL_NAME = 'llama3-8b'

        watsonx_llm = WatsonxLLM(
            model_id=MODEL_ID_list[MODEL_NAME],
            url="https://us-south.ml.cloud.ibm.com",
            project_id=PROJECT_ID,
            params=parameters,
        )

        # íšŒì˜ ê¸°ì—¬ë„ ë¶„ì„ ì‹¤í–‰
        contribution_scores, contribution_chart_buf = perform_contribution_analysis(chat_logs)

        # ê²°ê³¼ ì´ë¯¸ì§€ ì—…ë¡œë“œ
        contribution_chart_upload = client.files_upload_v2(
            channel=channel_id,
            file=contribution_chart_buf,
            filename='contribution_analysis.png',
            title='íšŒì˜ ê¸°ì—¬ë„ ë¶„ì„ ê²°ê³¼'
        )

        # ë¶„ì„ ê²°ê³¼ ë¸”ë¡ ìƒì„±
        blocks = format_contribution_blocks(contribution_scores)

        # ë¶„ì„ ê²°ê³¼ ë©”ì‹œì§€ ì „ì†¡
        client.chat_postMessage(
            channel=channel_id,
            blocks=blocks,
            text="íšŒì˜ ê¸°ì—¬ë„ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤!"
        )

        # if contribution_chart_upload['ok']:
        #     # ì—…ë¡œë“œëœ íŒŒì¼ì˜ ì •ë³´
        #     contribution_file_info = contribution_chart_upload['file']
        #     contribution_file_url = contribution_file_info.get('permalink_public')  # ê³µê°œ URL í™•ë³´

        #     if not contribution_file_url:
        #         # permalink_publicì´ ì—†ëŠ” ê²½ìš°
        #         client.chat_postMessage(
        #             channel=channel_id,
        #             text="ì•—! ì´ë¯¸ì§€ë¥¼ ê³µê°œì ìœ¼ë¡œ ê³µìœ í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”."
        #         )
        #         return

        #     # ë¶„ì„ ê²°ê³¼ ë¸”ë¡ ìƒì„±
        #     blocks = format_contribution_blocks(contribution_scores)

        #     blocks.append(
        #         {
        #             "type": "image",
        #             "image_url": contribution_file_url,
        #             "alt_text": "íšŒì˜ ê¸°ì—¬ë„ ë¶„ì„ ê·¸ë˜í”„"
        #         }
        #     )

        #     # ë¶„ì„ ê²°ê³¼ ë©”ì‹œì§€ ì „ì†¡
        #     client.chat_postMessage(
        #         channel=channel_id,
        #         blocks=blocks,
        #         text="íšŒì˜ ê¸°ì—¬ë„ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤!"
        #     )
        # else:
        #     client.chat_postMessage(
        #         channel=channel_id,
        #         text="ì•—! ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ëŠ” ì¤‘ì— ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”."
        #     )
    except SlackApiError as e:
        print(f"Slack API error: {e.response['error']}")
        client.chat_postMessage(
            channel=channel_id,
            text="ì•—! Slack API ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”."
        )
    except Exception as e:
        print(f"Error in handle_contribution_analysis: {e}")
        client.chat_postMessage(
            channel=channel_id,
            text="ì•—! íšŒì˜ ê¸°ì—¬ë„ ë¶„ì„ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”."
        )

def format_contribution_blocks(contribution_scores):
    # ì‚¬ìš©ìë³„ ì ìˆ˜ ë¦¬ìŠ¤íŠ¸ ìƒì„± ë° ì´í•© ê³„ì‚°
    user_list = []
    for user_id, scores in contribution_scores.items():
        total_sum = scores['discussion'] + scores['direction'] + scores['goal'] + scores['collaboration']
        user_list.append((user_id, scores, total_sum))

    # ì´í•© ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    sorted_user_list = sorted(user_list, key=lambda x: x[2], reverse=True)

    if not sorted_user_list:
        # ì‚¬ìš©ì ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°
        return []

    # íŒ€ì¥ ì¶”ì²œ (ê°€ì¥ ë†’ì€ í•©ê³„ë¥¼ ê°€ì§„ ì‚¬ìš©ì)
    top_user = sorted_user_list[0][1]  # scores dict
    top_user_id = sorted_user_list[0][0]
    top_user_sum = sorted_user_list[0][2]

    leader_block = {
        "type": "section",
        "text": {
            "type": "mrkdwn",
            "text": f"*íŒ€ì¥ ì¶”ì²œ:* <@{top_user_id}> ({top_user['username']}) ë‹˜!\në•ë¶„ì— ìš°ë¦¬ íŒ€ì´ ë°êµ´ë°êµ´ ì˜ êµ´ëŸ¬ê°€ìš”! ğŸ¢ğŸ’¨\nì´ ì ìˆ˜: {top_user_sum}ì  ğŸ¥‡"
        }
    }

    # ì‚¬ìš©ìë³„ ì ìˆ˜ ë¸”ë¡ ìƒì„± (ì •ë ¬ëœ ìˆœì„œëŒ€ë¡œ)
    user_blocks = []
    for user_id, scores, total_sum in sorted_user_list:
        text = (
            f"*{scores['username']}* ë‹˜:\n"
            f"â€¢ í† ë¡  ìœ ë„: {scores['discussion']}ì \n"
            f"â€¢ íšŒì˜ ë°©í–¥: {scores['direction']}ì \n"
            f"â€¢ ëª©í‘œ ë‹¬ì„±: {scores['goal']}ì \n"
            f"â€¢ í˜‘ì—… ì´‰ì§„: {scores['collaboration']}ì \n"
            f"â€¢ ì´ ì ìˆ˜: {total_sum}ì "
        )
        user_blocks.append({
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": text
            }
        })
        user_blocks.append({"type": "divider"})

    # ì „ì²´ í†µê³„ ê³„ì‚°
    total_discussion = sum(scores['discussion'] for scores in contribution_scores.values())
    total_direction = sum(scores['direction'] for scores in contribution_scores.values())
    total_goal = sum(scores['goal'] for scores in contribution_scores.values())
    total_collaboration = sum(scores['collaboration'] for scores in contribution_scores.values())
    user_count = len(contribution_scores)
    average_discussion = total_discussion / user_count if user_count > 0 else 0
    average_direction = total_direction / user_count if user_count > 0 else 0
    average_goal = total_goal / user_count if user_count > 0 else 0
    average_collaboration = total_collaboration / user_count if user_count > 0 else 0

    # ì „ì²´ í†µê³„ ë¸”ë¡ ìƒì„±
    stats_block = {
        "type": "section",
        "fields": [
            {
                "type": "mrkdwn",
                "text": f"*ì´ í† ë¡  ìœ ë„ ì ìˆ˜:* {total_discussion}ì "
            },
            {
                "type": "mrkdwn",
                "text": f"*í‰ê·  í† ë¡  ìœ ë„ ì ìˆ˜:* {average_discussion:.2f}ì "
            },
            {
                "type": "mrkdwn",
                "text": f"*ì´ íšŒì˜ ë°©í–¥ ì ìˆ˜:* {total_direction}ì "
            },
            {
                "type": "mrkdwn",
                "text": f"*í‰ê·  íšŒì˜ ë°©í–¥ ì ìˆ˜:* {average_direction:.2f}ì "
            },
            {
                "type": "mrkdwn",
                "text": f"*ì´ ëª©í‘œ ë‹¬ì„± ì ìˆ˜:* {total_goal}ì "
            },
            {
                "type": "mrkdwn",
                "text": f"*í‰ê·  ëª©í‘œ ë‹¬ì„± ì ìˆ˜:* {average_goal:.2f}ì "
            },
            {
                "type": "mrkdwn",
                "text": f"*ì´ í˜‘ì—… ì´‰ì§„ ì ìˆ˜:* {total_collaboration}ì "
            },
            {
                "type": "mrkdwn",
                "text": f"*í‰ê·  í˜‘ì—… ì´‰ì§„ ì ìˆ˜:* {average_collaboration:.2f}ì "
            }
        ]
    }

    # ë¸”ë¡ ë¦¬ìŠ¤íŠ¸ ìƒì„±
    blocks = [
        {
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": "*íšŒì˜ ê¸°ì—¬ë„ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤!* :sparkles:"
            }
        },
        {"type": "divider"},
        stats_block,
        {"type": "divider"},
        leader_block,
        {"type": "divider"}
    ]

    # ì‚¬ìš©ìë³„ ì ìˆ˜ ë¸”ë¡ ì¶”ê°€
    blocks.extend(user_blocks)

    return blocks


# ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„
if __name__ == '__main__':
    app.run(debug=True)
